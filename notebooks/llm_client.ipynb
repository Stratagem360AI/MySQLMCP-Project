{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# llm_client.py - LLM Integration\n",
    "# ==================================================\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import json\n",
    "import asyncio\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMClient(ABC):\n",
    "    \"\"\"Abstract base class for LLM clients\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def generate_sql(self, natural_query: str, schema_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate SQL from natural language query\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def explain_query(self, sql_query: str, schema_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Explain what a SQL query does in natural language\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import LLMConfig\n",
    "\n",
    "\n",
    "class OpenAIClient(LLMClient):\n",
    "    \"\"\"OpenAI LLM client\"\"\"\n",
    "    \n",
    "    def __init__(self, config: LLMConfig):\n",
    "        self.config = config\n",
    "        try:\n",
    "            import openai\n",
    "            self.client = openai.AsyncOpenAI(api_key=config.api_key)\n",
    "        except ImportError:\n",
    "            raise ImportError(\"OpenAI package not installed. Install with: pip install openai\")\n",
    "    \n",
    "    async def generate_sql(self, natural_query: str, schema_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate SQL from natural language using OpenAI\"\"\"\n",
    "        schema_text = self._format_schema(schema_info)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a SQL expert. Convert the following natural language query into a MySQL SQL query.\n",
    "\n",
    "Database Schema:\n",
    "{schema_text}\n",
    "\n",
    "Natural Language Query: {natural_query}\n",
    "\n",
    "Rules:\n",
    "1. Return ONLY the SQL query, no explanations\n",
    "2. Use proper MySQL syntax\n",
    "3. Use backticks for table/column names if needed\n",
    "4. Be precise and efficient\n",
    "5. If the query is ambiguous, make reasonable assumptions\n",
    "6. For aggregations, include appropriate GROUP BY clauses\n",
    "\n",
    "SQL Query:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await self.client.chat.completions.create(\n",
    "                model=self.config.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=self.config.max_tokens,\n",
    "                temperature=self.config.temperature\n",
    "            )\n",
    "            \n",
    "            sql_query = response.choices[0].message.content.strip()\n",
    "            # Clean up the response (remove markdown formatting if present)\n",
    "            if sql_query.startswith('```'):\n",
    "                sql_query = sql_query.split('\\n', 1)[1]\n",
    "            if sql_query.endswith('```'):\n",
    "                sql_query = sql_query.rsplit('\\n', 1)[0]\n",
    "            \n",
    "            return sql_query.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating SQL with OpenAI: {e}\")\n",
    "            return f\"-- Error: Could not generate SQL query: {str(e)}\"\n",
    "    \n",
    "    async def explain_query(self, sql_query: str, schema_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Explain SQL query in natural language\"\"\"\n",
    "        schema_text = self._format_schema(schema_info)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Explain this SQL query in simple, natural language:\n",
    "\n",
    "Database Schema:\n",
    "{schema_text}\n",
    "\n",
    "SQL Query: {sql_query}\n",
    "\n",
    "Provide a clear, concise explanation of what this query does.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await self.client.chat.completions.create(\n",
    "                model=self.config.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=self.config.max_tokens,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error explaining query with OpenAI: {e}\")\n",
    "            return f\"Error: Could not explain query: {str(e)}\"\n",
    "    \n",
    "    def _format_schema(self, schema_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format schema information for the LLM prompt\"\"\"\n",
    "        if \"schema\" not in schema_info:\n",
    "            return \"No schema information available\"\n",
    "        \n",
    "        formatted_tables = []\n",
    "        for table_name, columns in schema_info[\"schema\"].items():\n",
    "            column_info = []\n",
    "            for col in columns:\n",
    "                col_desc = f\"  - {col['Field']} ({col['Type']})\"\n",
    "                if col['Key'] == 'PRI':\n",
    "                    col_desc += \" [PRIMARY KEY]\"\n",
    "                if col['Null'] == 'NO':\n",
    "                    col_desc += \" [NOT NULL]\"\n",
    "                column_info.append(col_desc)\n",
    "            \n",
    "            formatted_tables.append(f\"Table: {table_name}\\n\" + \"\\n\".join(column_info))\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted_tables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
